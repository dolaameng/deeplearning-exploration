{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varational autoencoder by RNN for sudoku sequence generation\n",
    "\n",
    "## dataset \n",
    "- [10,000 solved sudoku](http://www.printable-sudoku-puzzles.com/wfiles/)\n",
    "- [bigger dataset: 1M sudoku and solutions](https://www.kaggle.com/bryanpark/sudoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sudoku training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symbol2index = dict(zip('123456789', range(9)))\n",
    "index2symbol = dict(zip(range(9), '123456789'))\n",
    "\n",
    "def puzzle2tensor(puzzle_batch):\n",
    "    batch_size = len(puzzle_batch)\n",
    "    seq_len = len(puzzle_batch[0])\n",
    "    t = torch.zeros([batch_size, seq_len, 9])\n",
    "    for r in range(batch_size):\n",
    "        for c in range(seq_len):\n",
    "            s = symbol2index[puzzle_batch[r][c]]\n",
    "            t[r, c, s] = 1\n",
    "    return t\n",
    "\n",
    "def puzzle2target(puzzle_batch):\n",
    "    batch_size = len(puzzle_batch)\n",
    "    seq_len = len(puzzle_batch[0])\n",
    "    t = torch.LongTensor(batch_size, seq_len).zero_()\n",
    "    for r in range(batch_size):\n",
    "        for c in range(seq_len):\n",
    "            s = symbol2index[puzzle_batch[r][c]]\n",
    "            t[r, c] = s\n",
    "    return t\n",
    "\n",
    "def tensor2puzzle(tensors):\n",
    "    \"\"\"tensors.size() == [batch_size, seq, 9]\n",
    "    \"\"\"\n",
    "    _, p = tensors.max(dim=2)\n",
    "    p = p.squeeze().numpy()\n",
    "    puzzles = []\n",
    "    for r in p:\n",
    "        puzzles.append(''.join([index2symbol.get(s) for s in r]))\n",
    "    return puzzles\n",
    "\n",
    "def output2puzzle(y):\n",
    "    \"\"\"y.size() == [batch_size, 9]\n",
    "    \"\"\"\n",
    "    _, labels = y.max(dim=1)\n",
    "    return labels.numpy().squeeze() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## build a sudoku env following openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sudoku(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"return observation\"\"\"\n",
    "        self.state = []\n",
    "        obs = ''.join(self.state)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"action: '123456789'\n",
    "        return [obs, reward, done, info]\"\"\"\n",
    "        self.state.append(action)\n",
    "        obs = ''.join(self.state)\n",
    "        reward = 1\n",
    "        valid, info = self.is_valid(self.state)\n",
    "        done = not valid\n",
    "        return [obs, reward, done, info]\n",
    "    \n",
    "    def is_valid(self, puzzle):\n",
    "        \"\"\"puzzle: an array of digits.\n",
    "        Check if a partial puzzle is valid\n",
    "        TODO: DONT REALLY NEED TO CHECK ALL BUT THE LAST ELEMENT\n",
    "        \"\"\"\n",
    "        nrows = int(np.ceil(len(puzzle)/9))\n",
    "        for r in range(0, nrows):\n",
    "            row = puzzle[r*9:(r+1)*9]\n",
    "            if len(row) != len(set(row)):\n",
    "                return False, \"row rule\"\n",
    "        for c in range(0, 9):\n",
    "            col = puzzle[c:c+9*9:9]\n",
    "            if len(col) != len(set(col)):\n",
    "                return False, \"col rule\"\n",
    "        strides = [list(range(0, 3)), list(range(3, 6)), list(range(6, 9))]\n",
    "        squares = [(r, c) for r in strides for c in strides]\n",
    "        for sqr, sqc in squares:\n",
    "            sqi = [r*9+c for r in sqr for c in sqc]\n",
    "            square = [puzzle[i] for i in sqi if i < len(puzzle)]\n",
    "            if len(square) != len(set(square)):\n",
    "                return False, \"sqr rule\"\n",
    "        return True, \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sudoku(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"return observation\"\"\"\n",
    "        self.state = []\n",
    "        obs = ''.join(self.state)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"action: '123456789'\n",
    "        return [obs, reward, done, info]\"\"\"\n",
    "        self.state.append(action)\n",
    "        obs = ''.join(self.state)\n",
    "        reward = 1\n",
    "        valid, info = self.is_valid(self.state)\n",
    "        done = not valid\n",
    "        return [obs, reward, done, info]\n",
    "    \n",
    "    def is_valid(self, puzzle):\n",
    "        \"\"\"puzzle: an array of digits.\n",
    "        ONLY check last element\n",
    "        \"\"\"\n",
    "        pivot = len(puzzle) - 1\n",
    "        nrows = int(np.ceil(len(puzzle)/9))\n",
    "        for r in range(0, nrows):\n",
    "            ri = range(r*9, (r+1)*9)\n",
    "            if pivot not in set(ri): continue\n",
    "            row = puzzle[r*9:(r+1)*9]\n",
    "            if len(row) != len(set(row)):\n",
    "                return False, \"row rule\"\n",
    "        for c in range(0, 9):\n",
    "            ci = range(c, c+9*9, 9)\n",
    "            if pivot not in set(ci): continue\n",
    "            col = puzzle[c:c+9*9:9]\n",
    "            if len(col) != len(set(col)):\n",
    "                return False, \"col rule\"\n",
    "        strides = [list(range(0, 3)), list(range(3, 6)), list(range(6, 9))]\n",
    "        squares = [(r, c) for r in strides for c in strides]\n",
    "        for sqr, sqc in squares:\n",
    "            sqi = [r*9+c for r in sqr for c in sqc]\n",
    "            if pivot not in set(sqi): continue\n",
    "            square = [puzzle[i] for i in sqi if i < len(puzzle)]\n",
    "            if len(square) != len(set(square)):\n",
    "                return False, \"sqr rule\"\n",
    "        return True, \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1', 1, False, 'valid']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Sudoku()\n",
    "print(env.reset())\n",
    "env.step('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'valid')\n",
      "(True, 'valid')\n",
      "(False, 'col rule')\n"
     ]
    }
   ],
   "source": [
    "# won't work with new version is_valid\n",
    "puzzle = list(\"123456789987654321\")\n",
    "print(env.is_valid(puzzle))\n",
    "puzzle = list(\"123456\")\n",
    "print(env.is_valid(puzzle[:-5]))\n",
    "puzzle = list(\"1234567891\")\n",
    "print(env.is_valid(puzzle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## baseline - random generator policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_policy():\n",
    "    return np.random.choice( list(\"123456789\"), 1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "\n",
    "env = Sudoku()\n",
    "\n",
    "for game in range(5000):\n",
    "    obs = env.reset()\n",
    "    game_reward = 0\n",
    "    for _ in range(81):\n",
    "        action = random_policy()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        game_reward += reward\n",
    "        if done: break\n",
    "    all_rewards.append(game_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmCEgSQ0zBCSpYf8fqD1sQVrNWwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff536abd898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SudokuPolicy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuPolicy, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=9, hidden_size=100,\n",
    "                          num_layers=1, bidirectional=False,\n",
    "                          batch_first=True)\n",
    "        self.fc1 = nn.Linear(100, 32)\n",
    "        self.elu = nn.ELU()\n",
    "#         self.d = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 9)\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, obs):\n",
    "        batch_size, seq_len, input_size = obs.size()\n",
    "        h0 = Variable(torch.zeros(1, batch_size, 100)).cuda()\n",
    "        out, _ = self.rnn(obs, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.elu(self.fc1(out))\n",
    "#         out = self.d(out)\n",
    "        logits = self.fc2(out)\n",
    "        # probs and labels for action calculation\n",
    "        probs = self.softmax(logits)\n",
    "        self.label = torch.multinomial(probs, 1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1359  0.0144 -0.0451 -0.1487 -0.0381  0.0867  0.0745 -0.1115  0.0085\n",
      "[torch.cuda.FloatTensor of size 1x9 (GPU 0)]\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "actions = \"123456789\"\n",
    "\n",
    "m = SudokuPolicy().cuda()\n",
    "obs = Variable(puzzle2tensor([\"12\"])).cuda()\n",
    "print( m(obs) )\n",
    "print( actions[m.label.data.cpu().numpy()[0][0]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## credit assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate):\n",
    "    \"\"\"rewards: rewards of all steps for a single game, a list\n",
    "    \"\"\"\n",
    "    discounted_rewards = np.empty(len(rewards),dtype=np.float32)\n",
    "    accum_reward = 0\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        accum_reward = rewards[i] + accum_reward * discount_rate\n",
    "        discounted_rewards[i] = accum_reward\n",
    "    return discounted_rewards\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    \"\"\"\n",
    "    all_rewards: rewards of all games for all steps, a list of list\n",
    "    \"\"\"\n",
    "    discounted_all_rewards = [discount_rewards(rewards, discount_rate)\n",
    "                             for rewards in all_rewards]\n",
    "    flatten_rewards = [reward for rewards in discounted_all_rewards\n",
    "                          for reward in rewards]\n",
    "    reward_mean = np.mean(flatten_rewards)\n",
    "    reward_std = np.std(flatten_rewards)\n",
    "    normalized_rewards = [(rewards - reward_mean) / reward_std\n",
    "                         for rewards in discounted_all_rewards]\n",
    "    return normalized_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22., -40., -50.], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rewards([10, 0, -50], discount_rate=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.28435072, -0.86597717, -1.18910301], dtype=float32),\n",
       " array([ 1.2666533 ,  1.07277775], dtype=float32)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_and_normalize_rewards([[10, 0, -50], [10, 20]],\n",
    "                               discount_rate=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training by policy gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SudokuPolicy (\n",
       "  (rnn): GRU(9, 100, batch_first=True)\n",
       "  (fc1): Linear (100 -> 32)\n",
       "  (elu): ELU (alpha=1.0)\n",
       "  (fc2): Linear (32 -> 9)\n",
       "  (softmax): Softmax ()\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = nn.CrossEntropyLoss()\n",
    "\n",
    "model = SudokuPolicy().cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4 7\n",
      "25 5.26 8\n",
      "50 6.24 8\n",
      "75 6.64 8\n",
      "100 7.2 12\n",
      "125 8.56 17\n",
      "150 10.92 18\n",
      "175 10.84 17\n",
      "200 11.94 17\n",
      "225 10.9 17\n",
      "250 10.44 17\n",
      "275 12.08 17\n",
      "300 11.22 17\n",
      "325 11.76 17\n",
      "350 11.06 17\n",
      "375 11.48 17\n",
      "400 10.52 17\n",
      "425 11.66 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-b7fb8390b94e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nn_epochs = 600\\nn_max_steps = 81\\nn_games_per_update = 50\\ndiscount_rate = .85\\n\\n\\n\\n\\noptimizer = optim.Adam(model.parameters(), lr=1e-2)\\nactions = \"123456789\"\\n\\n\\nfor epoch in range(n_epochs):\\n    \\n    all_losses = []\\n    all_rewards = []\\n    \\n    for game in range(n_games_per_update):\\n        \\n        game_losses = []\\n        game_rewards = []\\n        \\n        obs = env.reset()\\n        first_action = random_policy() # random first action\\n        obs, reward, done, info = env.step(first_action)\\n        \\n        for step in range(n_max_steps):\\n            # train on one observation\\n            obs_var = Variable(puzzle2tensor([obs])).cuda()\\n            model.zero_grad()\\n            logits = model(obs_var)\\n            label = model.label.data.cpu().numpy()[0][0]\\n            action = actions[label]\\n            obs, reward, done, info = env.step(action)\\n\\n            y = Variable(torch.LongTensor([int(label)])).cuda()\\n            loss = objective(logits, y)\\n            game_losses.append(loss)\\n            game_rewards.append(reward)\\n            if done:\\n                break\\n                \\n        all_losses.append(game_losses)\\n        all_rewards.append(game_rewards)\\n    \\n    ## normalize and discount rewards\\n    normalized_rewards = discount_and_normalize_rewards(all_rewards, discount_rate=discount_rate)\\n    ## aggregate losses\\n    weighted_loss = np.mean([all_losses[game][step] * float(normalized_rewards[game][step])\\n                        for game in range(len(normalized_rewards))\\n                        for step in range(len(normalized_rewards[game]))])\\n    model.zero_grad()\\n    weighted_loss.backward()\\n    ## optimize based on aggregated gradient\\n    optimizer.step()\\n    if epoch % 25 == 0:\\n        rewards = [np.sum(reward) for reward in all_rewards]\\n        mean_reward = np.mean(rewards)\\n        max_reward = np.max(rewards)\\n        print(epoch, mean_reward, max_reward)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dola/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/dola/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dola/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/dola/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    145\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 600\n",
    "n_max_steps = 81\n",
    "n_games_per_update = 50\n",
    "discount_rate = .95\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "actions = \"123456789\"\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    all_losses = []\n",
    "    all_rewards = []\n",
    "    \n",
    "    for game in range(n_games_per_update):\n",
    "        \n",
    "        game_losses = []\n",
    "        game_rewards = []\n",
    "        \n",
    "        obs = env.reset()\n",
    "        first_action = random_policy() # random first action\n",
    "        obs, reward, done, info = env.step(first_action)\n",
    "        \n",
    "        for step in range(n_max_steps):\n",
    "            # train on one observation\n",
    "            obs_var = Variable(puzzle2tensor([obs])).cuda()\n",
    "            model.zero_grad()\n",
    "            logits = model(obs_var)\n",
    "            label = model.label.data.cpu().numpy()[0][0]\n",
    "            action = actions[label]\n",
    "            obs, reward, done, info = env.step(action)\n",
    "\n",
    "            y = Variable(torch.LongTensor([int(label)])).cuda()\n",
    "            loss = objective(logits, y)\n",
    "            game_losses.append(loss)\n",
    "            game_rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        all_losses.append(game_losses)\n",
    "        all_rewards.append(game_rewards)\n",
    "    \n",
    "    ## normalize and discount rewards\n",
    "    normalized_rewards = discount_and_normalize_rewards(all_rewards, discount_rate=discount_rate)\n",
    "    ## aggregate losses\n",
    "    weighted_loss = np.mean([all_losses[game][step] * float(normalized_rewards[game][step])\n",
    "                        for game in range(len(normalized_rewards))\n",
    "                        for step in range(len(normalized_rewards[game]))])\n",
    "    model.zero_grad()\n",
    "    weighted_loss.backward()\n",
    "    ## optimize based on aggregated gradient\n",
    "    optimizer.step()\n",
    "    if epoch % 25 == 0:\n",
    "        rewards = [np.sum(reward) for reward in all_rewards]\n",
    "        mean_reward = np.mean(rewards)\n",
    "        max_reward = np.max(rewards)\n",
    "        print(epoch, mean_reward, max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = list('123456789')\n",
    "def model_policy(obs, model):\n",
    "    if len(obs) == 0:\n",
    "        return random_policy()\n",
    "    else:\n",
    "        obs_var = Variable(puzzle2tensor([obs])).cuda()\n",
    "        model.eval()\n",
    "        logits = model(obs_var)\n",
    "        label = model.label.data.cpu().numpy()[0][0]\n",
    "        action = actions[label]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "all_rewards = []\n",
    "all_solutions = []\n",
    "\n",
    "env = Sudoku()\n",
    "\n",
    "for game in tqdm_notebook(range(5000)):\n",
    "    obs = env.reset()\n",
    "    game_reward = 0\n",
    "    for _ in range(81):\n",
    "        action = model_policy(obs, model)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        game_reward += reward\n",
    "        if done: \n",
    "            all_solutions.append(obs)\n",
    "            break\n",
    "    all_rewards.append(game_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff522536a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2971465832'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solutions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "084d07edaa4545f39aa14213764e33c0": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "091cb96451bf486fb813c6d8bc3257a8": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0eaa4cfbbc494fd8bae72918ac92139b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "195376bb57e84faaafdb65cce1ece8d4": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1a773168bbbf442f99432d9c5fb2bc06": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1c3dbe6c49984c70835d920c3e9c4f07": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1c50b027bbe84d049c878ee4433fd216": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "277b831db02b4cc5b9ed433c6b4c3f5a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "30adc256f1b84e20b848d2c65f7c3e56": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "32591291ccea42ce97e7bbf007a14294": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "33583adbb30a4060a392e71138a5b0f0": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "34df177444bb40fba3c92699ec589598": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "4b5ba8da3d164be79426d064e4768595": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "4d5095b75bbd45f992538d7c847d5c44": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "559343ad277f405ba3322e6d99deb254": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "5a0276950ccd419988696db74b0394ef": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "5b40be1709cd425b9244aeb1c0a3237f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "61a0ee235162423f8a2c896b0c7ba984": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "6665d32265d7466d841e2a831bab99ce": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "67a3edf13c5444a89d5d9abc9b27ee68": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "6ab986d2300848cda264e7c49bbb8b13": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7541aeb81f9d45e8b27230d1c1c14146": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "75945b3fbac34746b22539cf31d52fa3": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "76a85c0e584745f699c92ef805595ed2": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7c1e576d8922484396b5d6571ec0aac6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7df37c80db034488a81778ab34baab95": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "841bab2ad75e4bd5a6c02ce837463fc8": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "87287fd737794d57b7f7c710bde6bca4": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "8d5bdf17eb104c0e9b0f6f03c42079d5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "8f266298f50441449c98def654ce9e85": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "90c9ac80a2b44e10a9de71633dbbcfa1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "97cbadf4ad4b4f979bc8b3078b2a69bf": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9b3b78ec521e4bd2b504bb3e137c0ed5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9e433d8023964f1fb76e70ab27336b7d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9ffb331fc4674af0b896d22828f02449": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "a7ef4365bdd84b52b1691954d07d16f6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "aad8756eccbb4ed98e04ddb9e31d53e0": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "acf4fac26b6b46a98f46bf2ad2026f65": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "afda566404d14dc5a31abc0ba91a6e06": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b1acca106f6a4fc5b2f758c10623fc44": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b393714ebbcb43a898a3620b900c2e06": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b5090e016214474f8be06b54d679af68": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b93ad7f59d2549c1973946ab58692691": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b9668054d425445c96f8fa2679adfc8e": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "bd44636c66f042aaa70b864fc96723c2": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "be77ec844c7742c49f2b0937abe5ab85": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c5c176f351404508960e5a9353940142": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "cd2f314ff1ad454c93b0d4989bdb11b4": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "cf89b68f0ff34c1eac62aaa25cc3f01f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "d1819ae830624700ba32be0815d14aa6": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "d22b624e512246f68422afce7f0f2b22": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "dc276d95f4bc4fa486881a4f4448be41": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "dffd90568d5348f7be562f40dac02ab1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f9311b94de6544eb912ff41e59e1d6c6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "ff791df6ec064f2f827c94c8414a429d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
