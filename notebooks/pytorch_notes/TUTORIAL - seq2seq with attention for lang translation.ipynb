{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq model with attention for language translation or chatbot?\n",
    "\n",
    "## some resources\n",
    "- [online tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb) and [code](https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation) from practical pytorch\n",
    "- MaximumEntropy [seq2seq-pytorch](https://github.com/MaximumEntropy/Seq2Seq-PyTorch)\n",
    "- IBM [pytorch seq2seq](https://github.com/IBM/pytorch-seq2seq)\n",
    "- [seq2seq.pytorch](https://github.com/eladhoffer/seq2seq.pytorch)\n",
    "- [seq2seq with tensorflow tutorials](https://github.com/ematvey/tensorflow-seq2seq-tutorials)\n",
    "- [seq2seq neural machine translation tutorial](https://github.com/tensorflow/nmt)\n",
    "- [chatbot based on seq2seq antilm](https://github.com/Marsan-Ma/tf_chatbot_seq2seq_antilm)\n",
    "- [practical seq2seq for chatbot](http://suriyadeepan.github.io/2016-12-31-practical-seq2seq/)\n",
    "\n",
    "## datasets\n",
    "- [Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/)\n",
    "- [chat corpus](https://github.com/Marsan-Ma/chat_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vanila basic seq2seq model\n",
    "### encoder: \n",
    "- a simple rnn (GRU/LSTM), some times with embedding layer before it\n",
    "- don't care about the output, instead, just take the last hidden state (called thought vector or context?)\n",
    "- input: batch of padded sequences (if of varying lengths), size=(batch_size, seq_len, input_dim) or (seq_len, batch_size, input_dim) depending on whether it is time_major or batch_major\n",
    "- output: the hidden state at the last step, size=(batch_size, hidden_dim)\n",
    "\n",
    "### decoder\n",
    "- a simple rnn, with a projection layer (softmax) after it, to map rnn seq output to vocab classification\n",
    "- the initial hidden state will be the thought vector, aka the last hidden state from encoder\n",
    "- for each step, the input should be the output from last step. And the input of first step for decoder will be a special mark, e.g., SOS (start of sentence) or just EOS\n",
    "- the sequence output will be projected by another one/sevearl layers to map them to class probablities\n",
    "\n",
    "### example\n",
    "- I will follow this [tutorial](https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb), trying to reverse the sequence by using a seq2seq model, in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[6 7 5 9 0] [9 5 7 6 1 0] 4\n"
     ]
    }
   ],
   "source": [
    "## generate some data: \n",
    "## input - a sequence of integers(index), target: the reverse of it\n",
    "## for vocabulary setup, reserving index 0 for padding and index 1 for EOS\n",
    "\n",
    "## this corresponds to skipping the vocab building (word2inex, index2word) and\n",
    "## use index directly\n",
    "class ReverseSeqData(data.Dataset):\n",
    "    def __init__(self, vocab_size=10, max_seq=10, n_data=1000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq = max_seq\n",
    "        self.n_data = n_data\n",
    "        self.seqs = []\n",
    "        self.seq_lens = []\n",
    "        for _ in range(n_data):\n",
    "            seq_len = np.random.randint(2, max_seq)\n",
    "            seq = np.zeros(max_seq).astype(np.int64)\n",
    "            seq[:seq_len] = np.random.randint(2, 10, seq_len) # 0, 1 reserved for padding and EOS\n",
    "            self.seqs.append(seq)\n",
    "            self.seq_lens.append(seq_len)\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "    def __getitem__(self, i):\n",
    "        seq = self.seqs[i]\n",
    "        seq_len = self.seq_lens[i]\n",
    "        target = np.zeros(self.max_seq + 1).astype(np.int64)\n",
    "        target[:seq_len+1] = np.array([x for x in seq[:seq_len][::-1]] + [1])\n",
    "        return (seq, target, seq_len)\n",
    "    \n",
    "toy_ds = ReverseSeqData(n_data=50000, max_seq=5)\n",
    "\n",
    "print(len(toy_ds))\n",
    "s, t, l = toy_ds[0]\n",
    "print(s, t, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model\n",
    "\n",
    "vector_dim = 8\n",
    "vocab_size = toy_ds.vocab_size\n",
    "\n",
    "class BasicSeq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BasicSeq2Seq, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, vector_dim, padding_idx=0)\n",
    "        self.encode = nn.GRU(input_size=8, hidden_size=vector_dim, num_layers=1, batch_first=True)\n",
    "        self.decode = nn.GRU(input_size=8, hidden_size=vector_dim, num_layers=1, batch_first=True)\n",
    "        self.project = nn.Linear(vector_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, seqs, seq_lens):\n",
    "        batch_size = seqs.size(0)\n",
    "        target_seq_len = seqs.size(1) + 1\n",
    "        embeded = self.embed(seqs)\n",
    "        \n",
    "        padded = pack_padded_sequence(embeded, seq_lens, batch_first=True)\n",
    "        h0 = Variable(torch.zeros([1, batch_size, vector_dim])).cuda()\n",
    "        _, h = self.encode(padded, h0)\n",
    "        \n",
    "        ys = []\n",
    "        # first input to decoder is EOS, which is 1 in index\n",
    "        y = Variable(torch.ones([batch_size, 1])).long().cuda()\n",
    "        y = self.embed(y)\n",
    "        for i in range(target_seq_len):\n",
    "            y, h = self.decode(y, h)\n",
    "            ys.append(y)\n",
    "        out = torch.cat(ys, dim=1)\n",
    "        \n",
    "        logits = self.project(out.view([-1, vector_dim]))\n",
    "        return logits.view([batch_size, target_seq_len, vocab_size])\n",
    "    \n",
    "def sort_seqs_by_len(*seqs, lens):\n",
    "    order = np.argsort(lens)[::-1]\n",
    "    sorted_seqs = []\n",
    "    for seq in seqs:\n",
    "        sorted_seqs.append(np.asarray(seq)[order])\n",
    "    return sorted_seqs + [np.asarray(lens)[order]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 5), (16, 6), torch.Size([16, 6, 10]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test model\n",
    "seqs, targets, lens = zip(*[toy_ds[i] for i in range(16)])\n",
    "# seqs = np.array(seqs)\n",
    "# targets = np.array(targets)\n",
    "# i = np.argsort(lens)[::-1]\n",
    "# seqs = seqs[i]\n",
    "# targets = targets[i]\n",
    "# lens = np.array(lens)[i]\n",
    "seqs, targets, lens = sort_seqs_by_len(seqs, targets, lens=lens)\n",
    "\n",
    "x = Variable(torch.from_numpy(seqs)).cuda()\n",
    "m = BasicSeq2Seq().cuda()\n",
    "y = m(x, lens)\n",
    "seqs.shape, targets.shape, y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training\n",
    "batch_size = 128\n",
    "n_batches = len(toy_ds) // batch_size\n",
    "n_epochs = 100\n",
    "\n",
    "objective = nn.CrossEntropyLoss()\n",
    "\n",
    "model = BasicSeq2Seq().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 2.2610697746276855\n",
      "0 195 1.464776635169983\n",
      "5 0 0.5823482275009155\n",
      "5 195 0.5377452969551086\n",
      "10 0 0.4125298857688904\n",
      "10 195 0.4034583568572998\n",
      "15 0 0.3362981379032135\n",
      "15 195 0.30488529801368713\n",
      "20 0 0.2657814025878906\n",
      "20 195 0.25782158970832825\n",
      "25 0 0.2263297140598297\n",
      "25 195 0.2644290626049042\n",
      "30 0 0.20293505489826202\n",
      "30 195 0.23257048428058624\n",
      "35 0 0.1814369410276413\n",
      "35 195 0.15772274136543274\n",
      "40 0 0.181661918759346\n",
      "40 195 0.13795605301856995\n",
      "45 0 0.15113674104213715\n",
      "45 195 0.14242248237133026\n",
      "50 0 0.10945641994476318\n",
      "50 195 0.11432357877492905\n",
      "55 0 0.14799422025680542\n",
      "55 195 0.1350439041852951\n",
      "60 0 0.11765176057815552\n",
      "60 195 0.11994931101799011\n",
      "65 0 0.10504516959190369\n",
      "65 195 0.12767396867275238\n",
      "70 0 0.10786114633083344\n",
      "70 195 0.08872746676206589\n",
      "75 0 0.0758020207285881\n",
      "75 195 0.09081286936998367\n",
      "80 0 0.08712781220674515\n",
      "80 195 0.07148434966802597\n",
      "85 0 0.0523664727807045\n",
      "85 195 0.06827341765165329\n",
      "90 0 0.05967968702316284\n",
      "90 195 0.05542568862438202\n",
      "95 0 0.05697206035256386\n",
      "95 195 0.05516284331679344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "index = np.arange(0, len(toy_ds))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    np.random.shuffle(index)\n",
    "    for b, bi in enumerate(np.array_split(index, n_batches)):\n",
    "        seqs, targets, lens = zip(*[toy_ds[i] for i in bi])\n",
    "        seqs, targets, lens = sort_seqs_by_len(seqs, targets, lens=lens)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(seqs)).cuda()\n",
    "        y = Variable(torch.from_numpy(targets)).cuda()\n",
    "        logits = model(x, lens)\n",
    "        \n",
    "        loss = objective(logits.view([-1, vocab_size]), y.view([-1]))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 5 == 0 and b % (n_batches//2) == 0:\n",
    "            print(epoch, b, loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## evaluation\n",
    "model.eval()\n",
    "seqs, targets, lens = zip(*[toy_ds[i] for i in range(20)])\n",
    "seqs, targets, lens = sort_seqs_by_len(seqs, targets, lens=lens)\n",
    "\n",
    "x = Variable(torch.from_numpy(seqs)).cuda()\n",
    "y = model(x, lens)\n",
    "_, label = torch.max(y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 6, 9, 9, 1, 0],\n",
       "       [5, 3, 5, 4, 1, 0],\n",
       "       [9, 3, 7, 4, 1, 0],\n",
       "       [8, 8, 8, 7, 1, 0],\n",
       "       [5, 9, 5, 6, 1, 0],\n",
       "       [9, 5, 7, 6, 1, 0],\n",
       "       [5, 8, 9, 1, 0, 0],\n",
       "       [2, 2, 6, 1, 0, 0],\n",
       "       [8, 6, 4, 1, 0, 0],\n",
       "       [2, 6, 3, 1, 0, 0],\n",
       "       [9, 7, 6, 1, 0, 0],\n",
       "       [6, 2, 4, 1, 0, 0],\n",
       "       [3, 7, 4, 1, 0, 0],\n",
       "       [3, 4, 5, 1, 0, 0],\n",
       "       [3, 4, 1, 0, 0, 0],\n",
       "       [8, 3, 1, 0, 0, 0],\n",
       "       [6, 9, 1, 0, 0, 0],\n",
       "       [6, 7, 1, 0, 0, 0],\n",
       "       [3, 4, 1, 0, 0, 0],\n",
       "       [7, 6, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 6, 9, 9, 1, 0],\n",
       "       [5, 3, 5, 4, 1, 0],\n",
       "       [9, 3, 7, 4, 1, 0],\n",
       "       [8, 8, 8, 7, 1, 0],\n",
       "       [5, 9, 8, 6, 1, 0],\n",
       "       [9, 5, 7, 6, 1, 0],\n",
       "       [5, 8, 9, 1, 0, 0],\n",
       "       [2, 2, 6, 1, 0, 0],\n",
       "       [8, 6, 4, 1, 0, 0],\n",
       "       [2, 6, 3, 1, 0, 0],\n",
       "       [9, 7, 6, 1, 0, 0],\n",
       "       [6, 2, 4, 1, 0, 0],\n",
       "       [3, 7, 4, 1, 0, 0],\n",
       "       [3, 4, 5, 1, 0, 0],\n",
       "       [3, 4, 1, 0, 0, 0],\n",
       "       [8, 3, 1, 0, 0, 0],\n",
       "       [6, 9, 1, 0, 0, 0],\n",
       "       [6, 7, 1, 0, 0, 0],\n",
       "       [3, 4, 1, 0, 0, 0],\n",
       "       [7, 6, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
