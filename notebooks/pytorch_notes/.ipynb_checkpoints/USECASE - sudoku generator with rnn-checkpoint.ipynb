{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RNN-GAN to generate sudoku\n",
    "\n",
    "## dataset \n",
    "- [10,000 solved sudoku](http://www.printable-sudoku-puzzles.com/wfiles/)\n",
    "\n",
    "***I didn't manage to get it work yet - at the end, the discriminator outperforms the geneator too much!***\n",
    "\n",
    "This is an example of how important the balance between generator/discriminator learning is in GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sudoku training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "puzzles = sum([open(f).readlines() \n",
    "               for f in glob(\"/home/dola/data/sudoku/solved/*.txt\")], [])\n",
    "puzzles = [p.strip() for p in puzzles if len(p.strip())==81]\n",
    "len(puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123456789578139624496872153952381467641297835387564291719623548864915372235748916'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check they are valid sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_sudoku(puzzle):\n",
    "    assert len(puzzle) == 81\n",
    "    p = np.array(list(puzzle)).reshape(9, 9)\n",
    "    rows = range(9)\n",
    "    cols = range(9)\n",
    "    digits = set('123456789')\n",
    "    strides = [slice(0, 3), slice(3, 6), slice(6, 9)]\n",
    "    squares = [(r, c) for r in strides for c in strides]\n",
    "    for r in rows:\n",
    "        assert set(p[r,:]) == digits, \"err: row %i\" % r\n",
    "    for c in cols:\n",
    "        assert set(p[:,c]) == digits, \"err: col %i\" % c\n",
    "    for sr, sc in squares:\n",
    "        assert set(p[sr, sc].ravel()) == digits, \"err: sqr %i %i\" % (sr, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789123456789123456789123456789123456789123456789123456789123456789123456789\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "err: col 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ecb38c9e82d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'123456789'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_sudoku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4bbe5d2f0307>\u001b[0m in \u001b[0;36mcheck_sudoku\u001b[0;34m(puzzle)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: row %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: col %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msquares\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: sqr %i %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: err: col 0"
     ]
    }
   ],
   "source": [
    "# negative example\n",
    "p = ''.join(['123456789'] * 9)\n",
    "print(p)\n",
    "check_sudoku(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in puzzles:\n",
    "    check_sudoku(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symbol2index = dict(zip('123456789', range(9)))\n",
    "index2symbol = dict(zip(range(9), '123456789'))\n",
    "\n",
    "def puzzle2tensor(puzzle_batch):\n",
    "    batch_size = len(puzzle_batch)\n",
    "    t = torch.rand([batch_size, 81, 9]) * 0.1\n",
    "    for r in range(batch_size):\n",
    "        for c in range(81):\n",
    "            s = symbol2index[puzzle_batch[r][c]]\n",
    "            t[r, c, s] = 0.9\n",
    "    return t\n",
    "\n",
    "def tensor2puzzle(tensors):\n",
    "    \"\"\"tensors.size() == [batch_size, 81, 9]\n",
    "    \"\"\"\n",
    "    _, p = tensors.max(dim=2)\n",
    "    p = p.squeeze().numpy()\n",
    "    puzzles = []\n",
    "    for r in p:\n",
    "        puzzles.append(''.join([index2symbol.get(s) for s in r]))\n",
    "    return puzzles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def set_params(self):\n",
    "        self.seq_len = 81\n",
    "        self.input_dim = 64\n",
    "\n",
    "        self.rnn_layer = 1\n",
    "        self.rnn_hidden_size = 128\n",
    "\n",
    "        self.fc1_hidden_size = 128\n",
    "\n",
    "        self.output_dim = 9\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.set_params()\n",
    "        self.rnn = nn.GRU(input_size=self.input_dim,\n",
    "                          hidden_size=self.rnn_hidden_size,\n",
    "                          num_layers=self.rnn_layer,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size, self.fc1_hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(self.fc1_hidden_size)\n",
    "        self.fc2 = nn.Linear(self.fc1_hidden_size, self.output_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.softmax= nn.Softmax()\n",
    "    def forward(self, x0):\n",
    "        batch_size = x0.size(0)\n",
    "        input_dim = x0.size(2)\n",
    "#         pads = Variable(torch.zeros([batch_size, self.seq_len-1, input_dim])).cuda()\n",
    "#         x = torch.cat([x0, pads], dim=1).contiguous()\n",
    "        x = x0\n",
    "        \n",
    "        h0 = Variable(torch.zeros([self.rnn_layer, batch_size, self.rnn_hidden_size])).cuda()\n",
    "        \n",
    "        \n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.contiguous()\n",
    "        out = out.view([-1, self.rnn_hidden_size])\n",
    "        out = self.fc1(out)\n",
    "        out = self.elu(out)\n",
    "#         out = self.bn1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        out = out.view([batch_size, self.seq_len, self.output_dim])\n",
    "        return out\n",
    "        \n",
    "generator = Generator().cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Generator(nn.Module):\n",
    "    def set_params(self):\n",
    "        self.seq_len = 81\n",
    "        self.input_dim = 16\n",
    "\n",
    "        self.rnn_layer = 3\n",
    "        self.rnn_hidden_size = 32\n",
    "\n",
    "        self.fc1_hidden_size = 64\n",
    "\n",
    "        self.output_dim = 9\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.set_params()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.fc1_hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(self.fc1_hidden_size)\n",
    "        self.fc2 = nn.Linear(self.fc1_hidden_size, self.output_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.softmax= nn.Softmax()\n",
    "    def forward(self, x0):\n",
    "        batch_size = x0.size(0)\n",
    "        seq_len = x0.size(1)\n",
    "        input_dim = x0.size(2)\n",
    "\n",
    "        x = x0.view([-1, generator.input_dim])\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.elu(out)\n",
    "#         out = self.bn1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        out = out.view([batch_size, seq_len, self.output_dim])\n",
    "        return out\n",
    "        \n",
    "generator = Generator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['333339933333884777777777773733973397567373593333393483777377697999892733333773788',\n",
       " '379997173447773333333331993313999933933988333395734373394733965778777773355739399']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "x0 = Variable(torch.randn([2, generator.seq_len, generator.input_dim])).cuda()\n",
    "generated = generator(x0)\n",
    "tensor2puzzle(generated.cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def set_params(self):\n",
    "        self.seq_len = 81\n",
    "        self.input_dim = 9\n",
    "        \n",
    "        self.rnn_layer = 1\n",
    "        self.rnn_hidden_size = 32\n",
    "        \n",
    "        self.fc1_hidden_size = 64\n",
    "        \n",
    "        self.output_dim = 1\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.set_params()\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=self.input_dim,\n",
    "                          hidden_size=self.rnn_hidden_size,\n",
    "                          num_layers=self.rnn_layer,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size*2, self.fc1_hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(self.fc1_hidden_size)\n",
    "        self.fc2 = nn.Linear(self.fc1_hidden_size, self.output_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = Variable(torch.zeros([self.rnn_layer*2, batch_size, self.rnn_hidden_size])).cuda()\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.elu(out)\n",
    "#         out = self.bn1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.5076\n",
       "  0.5061\n",
       " [torch.cuda.FloatTensor of size 2x1 (GPU 0)], Variable containing:\n",
       "  0.5056\n",
       "  0.5056\n",
       " [torch.cuda.FloatTensor of size 2x1 (GPU 0)])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "x_real = Variable(puzzle2tensor(puzzles[:2])).cuda()\n",
    "x_fake = generated\n",
    "discriminator(x_real), discriminator(x_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puzzles = np.array(puzzles)\n",
    "n = len(puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objective = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.387967586517334 0.6823969483375549\n",
      "0 30 1.3857080936431885 0.6892383098602295\n",
      "0 60 1.3826104402542114 0.6926155090332031\n",
      "1 0 1.3801488876342773 0.6955673098564148\n",
      "1 30 1.373881459236145 0.6996903419494629\n",
      "1 60 1.3694381713867188 0.6979137659072876\n",
      "2 0 1.363874912261963 0.7004465460777283\n",
      "2 30 1.3516838550567627 0.7063392996788025\n",
      "2 60 1.334257960319519 0.7186979651451111\n",
      "3 0 1.3199820518493652 0.728507399559021\n",
      "3 30 1.269355297088623 0.7603364586830139\n",
      "3 60 1.2026350498199463 0.7926214933395386\n",
      "4 0 1.1010921001434326 0.8623343110084534\n",
      "4 30 0.28382647037506104 2.0830180644989014\n",
      "4 60 0.03941308706998825 3.6772522926330566\n",
      "5 0 0.027451906353235245 4.0355401039123535\n",
      "5 30 0.019295286387205124 4.384931564331055\n",
      "5 60 0.014923274517059326 4.638742923736572\n",
      "6 0 0.013085928745567799 4.7688093185424805\n",
      "6 30 0.010758897289633751 4.960851669311523\n",
      "6 60 0.00905336532741785 5.129833221435547\n",
      "7 0 0.008300753310322762 5.222613334655762\n",
      "7 30 0.007140171714127064 5.365665912628174\n",
      "7 60 0.006263029761612415 5.496771335601807\n",
      "8 0 0.005819017067551613 5.57059907913208\n",
      "8 30 0.005196717567741871 5.686742782592773\n",
      "8 60 0.004645371809601784 5.795389175415039\n",
      "9 0 0.004361522849649191 5.8574347496032715\n",
      "9 30 0.00394367566332221 5.956189155578613\n",
      "9 60 0.003602650947868824 6.049763202667236\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    index = np.random.permutation(n)\n",
    "    n_batches = n // batch_size\n",
    "    for ib, batch_index in enumerate(np.array_split(index, n_batches)):\n",
    "        # train discriminator\n",
    "        puzzle_batch = puzzles[batch_index]\n",
    "        real_puzzles = Variable(puzzle2tensor(puzzle_batch)).cuda()\n",
    "        real_output = discriminator(real_puzzles)\n",
    "        real_labels = Variable(torch.ones(real_puzzles.size(0))).cuda()\n",
    "        \n",
    "        g_x0 = Variable(torch.randn([batch_size, 81, generator.input_dim])).cuda()\n",
    "        fake_puzzles = generator(g_x0)\n",
    "        fake_output = discriminator(fake_puzzles)\n",
    "        fake_labels = Variable(torch.zeros(fake_puzzles.size(0))).cuda()\n",
    "        \n",
    "        discriminator.zero_grad()\n",
    "        d_loss = objective(real_output, real_labels) + objective(fake_output, fake_labels)\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        ## train generator\n",
    "        g_x0 = Variable(torch.randn([batch_size, 81, generator.input_dim])).cuda()\n",
    "        fake_puzzles = generator(g_x0)\n",
    "        real_labels = Variable(torch.ones(fake_puzzles.size(0))).cuda()\n",
    "        d_output = discriminator(fake_puzzles)\n",
    "        \n",
    "        generator.zero_grad()\n",
    "        g_loss = objective(d_output, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if ib % 30 == 0:\n",
    "            print(epoch, ib, d_loss.data[0], g_loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Discriminator totally outperforms!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
