{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varational autoencoder by RNN for sudoku sequence generation\n",
    "\n",
    "## dataset \n",
    "- [10,000 solved sudoku](http://www.printable-sudoku-puzzles.com/wfiles/)\n",
    "- [bigger dataset: 1M sudoku and solutions](https://www.kaggle.com/bryanpark/sudoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sudoku training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "puzzles = sum([open(f).readlines() \n",
    "               for f in glob(\"123456789.txt\")], [])\n",
    "puzzles = [p.strip() for p in puzzles if len(p.strip())==81]\n",
    "len(puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "kaggle_sudoku = pd.read_csv(\"/home/dola/data/sudoku.csv\")\n",
    "puzzles = list(kaggle_sudoku.solutions)\n",
    "len(puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'864371259325849761971265843436192587198657432257483916689734125713528694542916378'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check they are valid sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_sudoku(puzzle):\n",
    "    assert len(puzzle) == 81\n",
    "    p = np.array(list(puzzle)).reshape(9, 9)\n",
    "    rows = range(9)\n",
    "    cols = range(9)\n",
    "    digits = set('123456789')\n",
    "    strides = [slice(0, 3), slice(3, 6), slice(6, 9)]\n",
    "    squares = [(r, c) for r in strides for c in strides]\n",
    "    for r in rows:\n",
    "        assert set(p[r,:]) == digits, \"err: row %i\" % r\n",
    "    for c in cols:\n",
    "        assert set(p[:,c]) == digits, \"err: col %i\" % c\n",
    "    for sr, sc in squares:\n",
    "        assert set(p[sr, sc].ravel()) == digits, \"err: sqr %i %i\" % (sr, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789123456789123456789123456789123456789123456789123456789123456789123456789\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "err: col 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ecb38c9e82d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'123456789'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_sudoku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4bbe5d2f0307>\u001b[0m in \u001b[0;36mcheck_sudoku\u001b[0;34m(puzzle)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: row %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: col %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msquares\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: sqr %i %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: err: col 0"
     ]
    }
   ],
   "source": [
    "# negative example\n",
    "p = ''.join(['123456789'] * 9)\n",
    "print(p)\n",
    "check_sudoku(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "for i in tqdm_notebook(range(len(puzzles))):\n",
    "    check_sudoku(puzzles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.41 s, sys: 104 ms, total: 1.52 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def augument(puzzles):\n",
    "    augumented = [p for p in puzzles]\n",
    "#     augumented += [p[::-1] for p in puzzles]\n",
    "    for p in puzzles:\n",
    "        p = np.array(list(p)).reshape([9, 9])\n",
    "        augumented.append(''.join(np.fliplr(p).ravel()))\n",
    "        p = p.T\n",
    "        augumented.append(''.join(p.ravel()))\n",
    "        augumented.append(''.join(np.fliplr(p).ravel()))\n",
    "        p = p.T\n",
    "        augumented.append(''.join(p.ravel()))\n",
    "        augumented.append(''.join(np.fliplr(p).ravel()))\n",
    "        p = p.T\n",
    "        augumented.append(''.join(p.ravel()))\n",
    "        augumented.append(''.join(np.fliplr(p).ravel()))\n",
    "    return augumented\n",
    "\n",
    "puzzles = augument(puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    }
   ],
   "source": [
    "print(len(puzzles))\n",
    "\n",
    "for p in puzzles:\n",
    "    check_sudoku(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symbol2index = dict(zip('123456789', range(9)))\n",
    "index2symbol = dict(zip(range(9), '123456789'))\n",
    "\n",
    "def puzzle2tensor(puzzle_batch):\n",
    "    batch_size = len(puzzle_batch)\n",
    "    seq_len = len(puzzle_batch[0])\n",
    "    t = torch.zeros([batch_size, seq_len, 9])\n",
    "    for r in range(batch_size):\n",
    "        for c in range(seq_len):\n",
    "            s = symbol2index[puzzle_batch[r][c]]\n",
    "            t[r, c, s] = 1\n",
    "    return t\n",
    "\n",
    "def puzzle2target(puzzle_batch):\n",
    "    batch_size = len(puzzle_batch)\n",
    "    seq_len = len(puzzle_batch[0])\n",
    "    t = torch.LongTensor(batch_size, seq_len).zero_()\n",
    "    for r in range(batch_size):\n",
    "        for c in range(seq_len):\n",
    "            s = symbol2index[puzzle_batch[r][c]]\n",
    "            t[r, c] = s\n",
    "    return t\n",
    "\n",
    "def tensor2puzzle(tensors):\n",
    "    \"\"\"tensors.size() == [batch_size, seq, 9]\n",
    "    \"\"\"\n",
    "    _, p = tensors.max(dim=2)\n",
    "    p = p.squeeze().numpy()\n",
    "    puzzles = []\n",
    "    for r in p:\n",
    "        puzzles.append(''.join([index2symbol.get(s) for s in r]))\n",
    "    return puzzles\n",
    "\n",
    "def output2puzzle(y):\n",
    "    \"\"\"y.size() == [batch_size, 9]\n",
    "    \"\"\"\n",
    "    _, labels = y.max(dim=1)\n",
    "    return labels.numpy().squeeze() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 9])\n",
      "['86437', '34617']\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "t = puzzle2tensor([p[:5] for p in puzzles[:2]])\n",
    "p = tensor2puzzle(t)\n",
    "print(t.size())\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 7  5  3  2  6\n",
       " 2  3  5  0  6\n",
       "[torch.LongTensor of size 2x5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "puzzle2target([p[:5] for p in puzzles[:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models - seq prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RnnVA(nn.Module):\n",
    "    \"\"\"RNN based Variational Autoencoder\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RnnVA, self).__init__()\n",
    "        self.input_size = 9\n",
    "        self.seq_len = 81\n",
    "        self.encoder_rnn_num_layers = 2\n",
    "        self.encoder_rnn_hidden_size = 128\n",
    "        self.encoder_fc1_hidden_size = 256\n",
    "        self.encoder_fc2_hidden_size = 256\n",
    "        self.va_size = 256\n",
    "        self.decoder_fc1_hidden_size = 256\n",
    "        self.decoder_rnn_num_layers = 1\n",
    "        self.decoder_rnn_hidden_size = 128\n",
    "        self.output_size = 9\n",
    "        \n",
    "        self.encoder_rnn = nn.GRU(input_size=self.input_size,\n",
    "                                  hidden_size=self.encoder_rnn_hidden_size,\n",
    "                                  num_layers=self.encoder_rnn_num_layers,\n",
    "                                  batch_first=True,\n",
    "                                  bidirectional=False)\n",
    "        self.encoder_fc1 = nn.Linear(self.encoder_rnn_hidden_size,\n",
    "                                    self.encoder_fc1_hidden_size)\n",
    "        self.encoder_fc2 = nn.Linear(self.encoder_fc1_hidden_size,\n",
    "                                    self.encoder_fc2_hidden_size)\n",
    "        self.elu = nn.ELU()\n",
    "        self.va_mean = nn.Linear(self.encoder_fc2_hidden_size, self.va_size)\n",
    "        self.va_gamma = nn.Linear(self.encoder_fc2_hidden_size, self.va_size)\n",
    "        self.decoder_fc1 = nn.Linear(self.va_size, self.decoder_fc1_hidden_size)\n",
    "        self.decoder_rnn = nn.GRU(input_size=self.decoder_fc1_hidden_size,\n",
    "                                 hidden_size=self.decoder_rnn_hidden_size,\n",
    "                                 num_layers=self.decoder_rnn_num_layers,\n",
    "                                 batch_first=True,\n",
    "                                 bidirectional=False)\n",
    "        self.decoder_classifier = nn.Linear(self.decoder_rnn_hidden_size,\n",
    "                                            self.output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        encode_h0 = Variable(torch.zeros([self.encoder_rnn_num_layers,\n",
    "                                   batch_size,\n",
    "                                   self.encoder_rnn_hidden_size])).cuda()\n",
    "        out, h = self.encoder_rnn(x, encode_h0)\n",
    "        out = out.contiguous().view([-1, self.encoder_rnn_hidden_size])\n",
    "        out = self.elu(self.encoder_fc1(out))\n",
    "        out = self.elu(self.encoder_fc2(out))\n",
    "        self.mean = self.va_mean(out)\n",
    "        self.gamma = self.va_gamma(out)\n",
    "        self.sigma = torch.exp(self.gamma * .5)\n",
    "        noise = Variable(torch.randn(self.sigma.size())).cuda()\n",
    "        h = self.mean + self.sigma * noise\n",
    "        out = self.elu(self.decoder_fc1(h))\n",
    "        out = out.view([batch_size, seq_len, -1])\n",
    "        decode_h0 = Variable(torch.zeros([self.decoder_rnn_num_layers,\n",
    "                                   batch_size,\n",
    "                                   self.decoder_rnn_hidden_size])).cuda()\n",
    "        out, h = self.decoder_rnn(out, decode_h0)\n",
    "        out = out.contiguous().view([-1, self.decoder_rnn_hidden_size])\n",
    "        logits = self.decoder_classifier(out)\n",
    "        probs = self.sigmoid(logits)\n",
    "        probs = probs.view([batch_size, seq_len, -1])\n",
    "        return probs\n",
    "    def generate(self, batch_size): \n",
    "        seq_len = 81\n",
    "        h = Variable(torch.randn([batch_size * seq_len, self.va_size])).cuda()\n",
    "        out = self.elu(self.decoder_fc1(h))\n",
    "        out = out.view([batch_size, seq_len, -1])\n",
    "        decode_h0 = Variable(torch.zeros([self.decoder_rnn_num_layers,\n",
    "                                   batch_size,\n",
    "                                   self.decoder_rnn_hidden_size])).cuda()\n",
    "        out, h = self.decoder_rnn(out, decode_h0)\n",
    "        out = out.contiguous().view([-1, self.decoder_rnn_hidden_size])\n",
    "        logits = self.decoder_classifier(out)\n",
    "        probs = self.sigmoid(logits)\n",
    "        probs = probs.view([batch_size, seq_len, -1])\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 81, 9]), torch.Size([2592, 256]), torch.Size([2592, 256]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RnnVA().cuda()\n",
    "x = Variable(torch.zeros([32, 81, 9])).cuda()\n",
    "y = model(x)\n",
    "y.size(), model.mean.size(), model.gamma.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 81, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['358833389399139797338337888888737397777333888888888383333797333783733337333938335',\n",
       " '779333311633337983389373877773397999898938888835893388378333338936878888899878933',\n",
       " '373933788777777733338988998883333899838978988558889338383989889998888888836693377',\n",
       " '537888788779883383438935388899838993988273387333333887787818787733839993337779339',\n",
       " '889998383877798868888899899967993998918895583883739987779353738873878399333888883',\n",
       " '888873883333387553399843338773839939388389747883488998888889887773779778333339999',\n",
       " '988333777833888888777333333731383833733138839333383333335988183357788988833311337',\n",
       " '787788338833383388585888787733388388887333377999378788888938797833377788889799773',\n",
       " '358888388588893339973339983398787788888388889383339988333113333998888733778511379',\n",
       " '333388888893838933233888999978887899889953337368333979937887778883888888883833333']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "generated = model.generate(10)\n",
    "print(generated.size())\n",
    "tensor2puzzle(generated.cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SudokuDataSet(Dataset):\n",
    "    def __init__(self, puzzles):\n",
    "        self.puzzles = puzzle2tensor(puzzles)\n",
    "    def __len__(self):\n",
    "        return self.puzzles.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.puzzles[i, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 s, sys: 1.06 s, total: 50.1 s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%time data = SudokuDataSet(puzzles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RnnVA (\n",
       "  (encoder_rnn): GRU(9, 128, num_layers=2, batch_first=True)\n",
       "  (encoder_fc1): Linear (128 -> 256)\n",
       "  (encoder_fc2): Linear (256 -> 256)\n",
       "  (elu): ELU (alpha=1.0)\n",
       "  (va_mean): Linear (256 -> 256)\n",
       "  (va_gamma): Linear (256 -> 256)\n",
       "  (decoder_fc1): Linear (256 -> 256)\n",
       "  (decoder_rnn): GRU(256, 128, batch_first=True)\n",
       "  (decoder_classifier): Linear (128 -> 9)\n",
       "  (sigmoid): Sigmoid ()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RnnVA().cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.6869287490844727 0.6853573322296143 0.0015713907778263092\n",
      "0 500 0.07329657673835754 0.0546133890748024 0.018683191388845444\n",
      "0 1000 0.032200321555137634 0.013167204335331917 0.019033119082450867\n",
      "0 1500 0.02408786304295063 0.004989929962903261 0.019097933545708656\n",
      "0 2000 0.022378552705049515 0.00337812933139503 0.019000424072146416\n",
      "0 2500 0.020982276648283005 0.0018435517558827996 0.019138725474476814\n",
      "0 3000 0.01959368586540222 0.0018789124442264438 0.01771477423608303\n",
      "0 3500 0.017221301794052124 0.0013526127440854907 0.015868689864873886\n",
      "0 4000 0.015896441414952278 0.001477017649449408 0.014419423416256905\n",
      "0 4500 0.016673315316438675 0.00212892796844244 0.014544387347996235\n",
      "0 5000 0.015405920334160328 0.0012989819515496492 0.014106938615441322\n",
      "0 5500 0.014674486592411995 0.0010229457402601838 0.013651540502905846\n",
      "0 6000 0.01421832013875246 0.0008640493033453822 0.013354270718991756\n",
      "0 6500 0.013682294636964798 0.000946232583373785 0.012736061587929726\n",
      "0 7000 0.013658950105309486 0.0008246439974755049 0.012834305875003338\n",
      "0 7500 0.013778232969343662 0.0007860808400437236 0.012992152012884617\n",
      "1 0 0.013844837434589863 0.0009423056035302579 0.012902531772851944\n",
      "1 500 0.013356880284845829 0.0006875227554701269 0.012669357471168041\n",
      "1 1000 0.013328674249351025 0.0005386555567383766 0.012790018692612648\n",
      "1 1500 0.013635978102684021 0.000783032679464668 0.012852945365011692\n",
      "1 2000 0.013479098677635193 0.000596000871155411 0.012883097864687443\n",
      "1 2500 0.013617550022900105 0.000673745118547231 0.012943805195391178\n",
      "1 3000 0.01343914307653904 0.00028725372976623476 0.01315188966691494\n",
      "1 3500 0.01359583716839552 0.0009795225923880935 0.012616314925253391\n",
      "1 4000 0.013506025075912476 0.0006249488797038794 0.012881075963377953\n",
      "1 4500 0.013154434971511364 0.0006562635535374284 0.01249817106872797\n",
      "1 5000 0.013556630350649357 0.0009674063767306507 0.012589223682880402\n",
      "1 5500 0.013179415836930275 0.000650073285214603 0.01252934243530035\n",
      "1 6000 0.013110032305121422 0.0004080066573806107 0.012702025473117828\n",
      "1 6500 0.013415341265499592 0.0008248437661677599 0.012590497732162476\n",
      "1 7000 0.013399560935795307 0.0009063659817911685 0.0124931950122118\n",
      "1 7500 0.013622822239995003 0.0007206059526652098 0.01290221605449915\n",
      "2 0 0.013367253355681896 0.0008878206717781723 0.012479432858526707\n",
      "2 500 0.01340267714112997 0.0005977507680654526 0.012804926373064518\n",
      "2 1000 0.01316196471452713 0.0004011000564787537 0.012760864570736885\n",
      "2 1500 0.013085857965052128 0.0004259002162143588 0.012659957632422447\n",
      "2 2000 0.013177596032619476 0.0005428934819065034 0.0126347029581666\n",
      "2 2500 0.013535295613110065 0.0008221755269914865 0.012713120318949223\n",
      "2 3000 0.01326577179133892 0.0004271160578355193 0.012838656082749367\n",
      "2 3500 0.013073030859231949 0.0003133083810098469 0.012759722769260406\n",
      "2 4000 0.013168448582291603 0.0006285032723098993 0.012539945542812347\n",
      "2 4500 0.013062995858490467 0.00046856977860443294 0.012594426050782204\n",
      "2 5000 0.01357756182551384 0.0007593952468596399 0.012818166986107826\n",
      "2 5500 0.013397468253970146 0.0008159609278663993 0.012581507675349712\n",
      "2 6000 0.01326691173017025 0.0004547904245555401 0.012812121771275997\n",
      "2 6500 0.013317742384970188 0.0006462331512011588 0.012671508826315403\n",
      "2 7000 0.013227632269263268 0.0006451476947404444 0.012582484632730484\n",
      "2 7500 0.013201847672462463 0.0005137202097103 0.012688127346336842\n",
      "3 0 0.013187400065362453 0.0006501810275949538 0.012537218630313873\n",
      "3 500 0.013074647635221481 0.0006111718248575926 0.012463475577533245\n",
      "3 1000 0.013390514068305492 0.0007784583140164614 0.012612055987119675\n",
      "3 1500 0.013277561403810978 0.0007966301636770368 0.012480931356549263\n",
      "3 2000 0.013047300279140472 0.0005587099585682154 0.0124885905534029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-23:\n",
      "Process Process-24:\n",
      "Process Process-22:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-21:\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 35, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dola/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-10078a1d9bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mrestore_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlatent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dola/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-6150a8b40e2e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mva_gamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_fc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "batches = DataLoader(data, batch_size=128, shuffle=True, num_workers=4)\n",
    "xentropy = nn.BCELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for b, batch in enumerate(batches):\n",
    "        x = Variable(batch).cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        xx = model(x)\n",
    "        restore_loss = xentropy(xx.view([-1, 9]), x.view([-1, 9]))\n",
    "        latent_loss = 0.5 * torch.mean(torch.exp(model.gamma) + model.mean*model.mean -1 - model.gamma)\n",
    "        loss = restore_loss + latent_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b % 500 == 0:\n",
    "            print(epoch, b, loss.data[0], restore_loss.data[0], latent_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generated_puzzles = tensor2puzzle(model.generate(10).cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['839142457983517148669418775773893255482886815236132119489648265767795791199359421',\n",
       " '467134614492673621933698721574684973228448167313726958646314479952274592924168257',\n",
       " '114726342615876993922421447967989344642814466978357984611758196647462461467161329',\n",
       " '254972914673464527561396759575252552173957545841127269826643517525487264427215953',\n",
       " '766553754832922653527878568411254457557921952977216315424359934552181374787154385',\n",
       " '234342868761257145872557745163983116811391597957484564868472411359214469618198138',\n",
       " '894191559625138577857145466382918997947861467296716321357318215768585416675975964',\n",
       " '945194212669111117762376876499474372722574679572558492927247748324616819344471649',\n",
       " '422943964256846866884981479744683575714365183542841247199147471251898136376164766',\n",
       " '288554218565177221675134621911393561932829729877683444436577951131495156537641457']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "err: row 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8f88306b00ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_sudoku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_puzzles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4bbe5d2f0307>\u001b[0m in \u001b[0;36mcheck_sudoku\u001b[0;34m(puzzle)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msquares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: row %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"err: col %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: err: row 0"
     ]
    }
   ],
   "source": [
    "check_sudoku(generated_puzzles[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "3c83309c19444e67ba4539f2efd20b75": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
