{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data into tensorflow graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resources\n",
    "- [tf doc - reading data](https://www.tensorflow.org/how_tos/reading_data/): three main ways\n",
    "- [tf doc - using queues and runners in mulitithreading](https://www.tensorflow.org/how_tos/threading_and_queues/): underlying mechanism for queues\n",
    "- [tutorial part1](https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/)\n",
    "- [tutorial part2](https://indico.io/blog/tensorflow-data-input-part2-extensions/)\n",
    "\n",
    "\n",
    "## get iris data\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data batch from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\r\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\r\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\r\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\r\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\r\n"
     ]
    }
   ],
   "source": [
    "!head -n  5 ../../data/iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_batch(csv_file, batch_size=64):\n",
    "    ## all start from a string_input_producer to fire up file names\n",
    "    files = tf.train.string_input_producer([csv_file])\n",
    "    ## reader - create symbolic row\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, row = reader.read(files)\n",
    "    ## parse/decode the row, default value specifies type and replacement for missing values\n",
    "    default_row = [[0.0], [0.0], [0.0], [0.0], [\"\"]] # floats for features and string for label\n",
    "#     sepal_len, sepal_wdh, pedal_len, pedal_wdh, label = tf.decode_csv(row, \n",
    "#                                                             record_defaults=default_row)\n",
    "#     x = tf.pack([sepal_len, sepal_wdh, pedal_len, pedal_wdh])\n",
    "    parsed_row = tf.decode_csv(row, record_defaults=default_row)\n",
    "    x = tf.pack(parsed_row[:4])\n",
    "    l = parsed_row[4]\n",
    "    y = tf.argmax(tf.to_int32(tf.pack([\n",
    "        tf.equal(l, \"Iris-setosa\"),\n",
    "        tf.equal(l, \"Iris-versicolor\"),\n",
    "        tf.equal(l, \"Iris-virginica\")\n",
    "    ])), 0)\n",
    "    # buffer data into batch\n",
    "    batch_x, batch_y = tf.train.shuffle_batch([x, y], batch_size=batch_size, \n",
    "                                              capacity=batch_size*5, \n",
    "                                              min_after_dequeue=2*batch_size)\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4) (64,)\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "\n",
    "sess = tf.Session()\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "\n",
    "bx, by = get_data_batch(path.abspath(\"../../data/iris.data\"))\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "bbx, bby = sess.run([bx, by])\n",
    "print(bbx.shape, bby.shape)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a simple model to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_logistic_regression(x, y):\n",
    "    w = tf.Variable(tf.zeros([4, 3]), dtype=tf.float32)\n",
    "    b = tf.Variable(tf.zeros([3]), dtype=tf.float32)\n",
    "    logits = tf.matmul(x, w) + b\n",
    "    yhat = tf.nn.softmax(logits)\n",
    "    label_hat = tf.arg_max(yhat, 1)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y)\n",
    "    \n",
    "    train_op = tf.train.AdamOptimizer(5e-3).minimize(loss)\n",
    "    test_op = tf.reduce_mean(tf.to_float(tf.equal(label_hat, y)))\n",
    "    predict_op = label_hat\n",
    "    \n",
    "    return train_op, test_op, predict_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.140625\n",
      "0.75\n",
      "0.890625\n",
      "0.921875\n",
      "1.0\n",
      "0.984375\n",
      "0.96875\n",
      "1.0\n",
      "1.0\n",
      "0.953125\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # create computing graph\n",
    "    # input, output\n",
    "    x, y = get_data_batch(path.abspath(\"../../data/iris.data\"))\n",
    "    # get model ops\n",
    "    train_op, test_op, predict_op = build_logistic_regression(x, y)\n",
    "    # initialize the graph\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # start the queue runner for data, by using multithread coord\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # train the model\n",
    "    for i in range(1000):\n",
    "        sess.run(train_op)\n",
    "        if i % 100 == 0:\n",
    "            print(sess.run(test_op))\n",
    "    \n",
    "    # stop the data queue, and gracely wait for all\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
